activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const { return v[i]; } //Yao: deleted override
activations/activation_function.h:    float_t df(float_t /*y*/) const  { return float_t(1); } //Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0.1), float_t(0.9)); } //Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const { return float_t(1) / (float_t(1) + std::exp(-v[i])); }  //Yao: deleted override
activations/activation_function.h:    float_t df(float_t y) const { return y * (float_t(1) - y); } //Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0.1), float_t(0.9)); } //Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const { return std::max(float_t(0), v[i]); } //Yao: deleted override
activations/activation_function.h:    float_t df(float_t y) const { return y > float_t(0) ? float_t(1) : float_t(0); } //Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0.1), float_t(0.9)); } //Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const { return (v[i] > float_t(0)) ? v[i] : float_t(0.01) * v[i]; }//Yao:deleted override
activations/activation_function.h:    float_t df(float_t y) const { return y > float_t(0) ? float_t(1) : float_t(0.01); }//Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0.1), float_t(0.9)); }//Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const  { return (v[i]<float_t(0) ? (exp(v[i])- float_t(1)) : v[i]); }//Yao: deleted override
activations/activation_function.h:    float_t df(float_t y) const { return (y > float_t(0) ? float_t(1) : (float_t(1)+y)); }//Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0.1), float_t(0.9)); }//Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const {//Yao: deleted override
activations/activation_function.h:    float_t df(float_t y) const {//Yao: deleted override
activations/activation_function.h:    virtual vec_t df(const vec_t& y, cnn_size_t index) const  {//Yao: deleted override
activations/activation_function.h:    virtual bool one_hot() const { return false; }//Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0), float_t(1)); }//Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const {//Yao: deleted override
activations/activation_function.h:    float_t df(float_t y) const { return float_t(1) - sqr(y); }//Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(-0.8), float_t(0.8)); }//Yao: deleted override
activations/activation_function.h:    float_t f(const vec_t& v, cnn_size_t i) const {//Yao: deleted override
activations/activation_function.h:    float_t df(float_t y) const { return 2 * y *(float_t(1) - y); }//Yao: deleted override
activations/activation_function.h:    std::pair<float_t, float_t> scale() const { return std::make_pair(float_t(0.1), float_t(0.9)); }//Yao: deleted override
core/kernels/fully_connected_grad_op.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/fully_connected_op.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/conv2d_op_opencl.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/conv2d_op_opencl.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/conv2d_op.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/conv2d_op_libdnn.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/conv2d_op_libdnn.h:    void compute(const core::OpKernelContext& context) override {
core/kernels/conv2d_grad_op.h:    void compute(const core::OpKernelContext& context) override {
core/backend_avx.h:                std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:                   std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:                std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:                  std::vector<tensor_t*>&        out_data) override {
core/backend_avx.h:                    std::vector<tensor_t*>&        out_data) override {
core/backend_avx.h:                     std::vector<tensor_t*>&        out_data) override {
core/backend_avx.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:                    std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:               std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_avx.h:               std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_avx.h:    backend_t type() const override { return backend_t::avx; }
core/backend_dnn.h:                std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                   std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                    std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                     std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:                    std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:               std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_dnn.h:               std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_dnn.h:    backend_t type() const override { return backend_t::libdnn; }
core/backend_nnp.h:                std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                   std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                    std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                     std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:                    std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:               std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_nnp.h:               std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_nnp.h:   backend_t type() const override { return backend_t::nnpack; }
core/backend_tiny.h:                std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:                   std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:                std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:                  std::vector<tensor_t*>&        out_data) override {
core/backend_tiny.h:                    std::vector<tensor_t*>&        out_data) override {
core/backend_tiny.h:                     std::vector<tensor_t*>&        out_data) override {
core/backend_tiny.h:                  std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:                    std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:               std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:                 std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:                  std::vector<tensor_t*>&       out_data) override {
core/backend_tiny.h:               std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:                 std::vector<tensor_t*>&       in_grad) override {
core/backend_tiny.h:    backend_t type() const override { return backend_t::tiny_dnn; }
layers/arithmetic_layer.h:    std::string layer_type() const override {
layers/arithmetic_layer.h:    std::vector<shape3d> in_shape() const override {
layers/arithmetic_layer.h:    std::vector<shape3d> out_shape() const override {
layers/arithmetic_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/arithmetic_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/average_unpooling_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/average_unpooling_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/average_unpooling_layer.h:    std::string layer_type() const override { return "ave-unpool"; }
layers/average_unpooling_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/average_unpooling_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/quantized_convolutional_layer.h:    size_t fan_in_size() const override {
layers/quantized_convolutional_layer.h:    size_t fan_out_size() const override  {
layers/quantized_convolutional_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/quantized_convolutional_layer.h:    out_shape() const override { return { params_.out, params_.out }; }
layers/quantized_convolutional_layer.h:    std::string layer_type() const override { return "q_conv"; }
layers/feedforward_layer.h:    std::pair<float_t, float_t> out_value_range() const { return h_.scale(); }//Yao: deleted override
layers/linear_layer.h:    std::vector<shape3d> in_shape() const override {
layers/linear_layer.h:    std::vector<shape3d> out_shape() const override {
layers/linear_layer.h:    std::string layer_type() const override { return "linear"; }
layers/linear_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/linear_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/linear_layer.h:   /* const vec_t& back_propagation_2nd(const vec_t& current_delta2) override {
layers/convolutional_layer.h:    size_t fan_in_size() const override {
layers/convolutional_layer.h:    size_t fan_out_size() const override  {
layers/convolutional_layer.h:                             std::vector<tensor_t*>&       out_data) override {
layers/convolutional_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/convolutional_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/convolutional_layer.h:    out_shape() const override { return { params_.out, params_.out }; }
layers/convolutional_layer.h:    std::string layer_type() const override {
layers/convolutional_layer.h:    std::string kernel_file() const override {
layers/convolutional_layer.h:    std::string kernel_header() const override {
layers/convolutional_layer.h:    void createOp() override {
layers/lrn_layer.h:    size_t fan_in_size() const override {
layers/lrn_layer.h:    size_t fan_out_size() const override {
layers/lrn_layer.h:    std::vector<shape3d> in_shape() const override {
layers/lrn_layer.h:    std::vector<shape3d> out_shape() const override {
layers/lrn_layer.h:    std::string layer_type() const override { return "norm"; }
layers/lrn_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/lrn_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/batch_normalization_layer.h:    size_t fan_in_size() const override {
layers/batch_normalization_layer.h:    size_t fan_out_size() const override {
layers/batch_normalization_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/batch_normalization_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/batch_normalization_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/batch_normalization_layer.h:        std::vector<tensor_t*>& out_data) override {
layers/batch_normalization_layer.h:    void set_context(net_phase ctx) override
layers/batch_normalization_layer.h:    std::string layer_type() const override { return "batch-norm"; }
layers/batch_normalization_layer.h:    virtual void post_update() override {
layers/batch_normalization_layer.h:    virtual void save(std::ostream& os) const override {
layers/batch_normalization_layer.h:    virtual void load(std::istream& is) override {
layers/batch_normalization_layer.h:    virtual void load(const std::vector<float_t>& src, int& idx) override {
layers/power_layer.h:    std::string layer_type() const override {
layers/power_layer.h:    std::vector<shape3d> in_shape() const override {
layers/power_layer.h:    std::vector<shape3d> out_shape() const override {
layers/power_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/power_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/max_unpooling_layer.h:    size_t fan_in_size() const override {
layers/max_unpooling_layer.h:    size_t fan_out_size() const override {
layers/max_unpooling_layer.h:                             std::vector<vec_t*>&       out_data)  override {
layers/max_unpooling_layer.h:                          std::vector<vec_t*>&       in_grad) override {
layers/max_unpooling_layer.h:    /*void back_propagation_2nd(const std::vector<vec_t>& delta_in) override {
layers/max_unpooling_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override { return {in_}; }
layers/max_unpooling_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override { return {out_, out_}; }
layers/max_unpooling_layer.h:    std::string layer_type() const override { return "max-unpool"; }
layers/max_unpooling_layer.h:    virtual void set_worker_count(cnn_size_t worker_count) override {
layers/max_pooling_layer.h:    size_t fan_in_size() const override {
layers/max_pooling_layer.h:    size_t fan_out_size() const override {
layers/max_pooling_layer.h:                             std::vector<tensor_t*>&       out_data) override {
layers/max_pooling_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/max_pooling_layer.h:    in_shape() const override { return { params_.in_ }; }
layers/max_pooling_layer.h:    out_shape() const override { return { params_.out_, params_.out_ }; }
layers/max_pooling_layer.h:    std::string layer_type() const override {
layers/max_pooling_layer.h:    std::string kernel_file() const override {
layers/max_pooling_layer.h:    void set_sample_count(cnn_size_t sample_count) override {
layers/quantized_deconvolutional_layer.h:    virtual size_t fan_in_size() const override {
layers/quantized_deconvolutional_layer.h:    virtual size_t fan_out_size() const override {
layers/quantized_deconvolutional_layer.h:                             std::vector<tensor_t*>&       out_data) override {
layers/quantized_deconvolutional_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/quantized_deconvolutional_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/quantized_deconvolutional_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/quantized_deconvolutional_layer.h:    std::string layer_type() const override { return "q_deconv"; }
layers/partial_connected_layer.h:    size_t fan_in_size() const override {
layers/partial_connected_layer.h:    size_t fan_out_size() const override {
layers/partial_connected_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/partial_connected_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/layer.h: * sub-class should override these methods:
layers/layer.h:     * override properly if the layer is intended to be used as output layer
layers/layer.h:     * override if the layer has trainable weights, and scale of initialization is important
layers/layer.h:     * override if the layer has trainable weights, and scale of initialization is important
layers/layer.h:    ///< so "visual" layer(like convolutional layer) should override this for better visualization.
layers/average_pooling_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/average_pooling_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/average_pooling_layer.h:    std::string layer_type() const override { return "ave-pool"; }
layers/average_pooling_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/average_pooling_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/deconvolutional_layer.h:    virtual size_t fan_in_size() const override {
layers/deconvolutional_layer.h:    virtual size_t fan_out_size() const override {
layers/deconvolutional_layer.h:                             std::vector<tensor_t*>&       out_data) override {
layers/deconvolutional_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/deconvolutional_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/deconvolutional_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/deconvolutional_layer.h:    std::string layer_type() const override { return "deconv"; }
layers/slice_layer.h:    std::string layer_type() const override {
layers/slice_layer.h:    std::vector<shape3d> in_shape() const override {
layers/slice_layer.h:    std::vector<shape3d> out_shape() const override {
layers/slice_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/slice_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/slice_layer.h:    void set_sample_count(cnn_size_t sample_count) override {
layers/dropout_layer.h:    size_t fan_in_size() const override
layers/dropout_layer.h:    size_t fan_out_size() const override
layers/dropout_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/dropout_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/dropout_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/dropout_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/dropout_layer.h:    void set_context(net_phase ctx) override
layers/dropout_layer.h:    std::string layer_type() const override { return "dropout"; }
layers/quantized_fully_connected_layer.h:    size_t fan_in_size() const override {
layers/quantized_fully_connected_layer.h:    size_t fan_out_size() const override {
layers/quantized_fully_connected_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/quantized_fully_connected_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/quantized_fully_connected_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/quantized_fully_connected_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/quantized_fully_connected_layer.h:    std::string layer_type() const override { return "q_fully-connected"; }
layers/fully_connected_layer.h:    size_t fan_in_size() const override {
layers/fully_connected_layer.h:    size_t fan_out_size() const override {
layers/fully_connected_layer.h:    std::vector<index3d<cnn_size_t>> in_shape() const override {
layers/fully_connected_layer.h:    std::vector<index3d<cnn_size_t>> out_shape() const override {
layers/fully_connected_layer.h:                             std::vector<tensor_t*>&       out_data) override {
layers/fully_connected_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
layers/fully_connected_layer.h:    std::string layer_type() const override { return "fully-connected"; }
layers/input_layer.h:    std::vector<shape3d> in_shape() const { return { shape_ }; }//Yao: deleted override
layers/input_layer.h:    std::vector<shape3d> out_shape() const  { return { shape_ }; }//Yao: deleted override
layers/input_layer.h:    std::string layer_type() const { return "input"; }//Yao: deleted override
layers/input_layer.h:                             std::vector<tensor_t*>& out_data)  { //Yao: deleted override
layers/input_layer.h:                          std::vector<tensor_t*>&       in_grad) { //Yao: deleted override
layers/concat_layer.h:    std::string layer_type() const override {
layers/concat_layer.h:    std::vector<shape3d> in_shape() const override {
layers/concat_layer.h:    std::vector<shape3d> out_shape() const override {
layers/concat_layer.h:                             std::vector<tensor_t*>& out_data) override {
layers/concat_layer.h:                          std::vector<tensor_t*>&       in_grad) override {
optimizers/optimizer.h:    virtual void reset() {} // override to implement pre-learning action
optimizers/optimizer.h:    void reset() {//Yao: deleted override
util/nn_error.h:    const char* error_what() const throw() { //Yao: Modified override function  
util/weight_init.h:    void fill(vec_t *weight, cnn_size_t fan_in, cnn_size_t fan_out) {//Yao: deleted override
util/weight_init.h:    void lecun_fill(vec_t *weight, cnn_size_t fan_in, cnn_size_t fan_out) { //Yao: deleted override
util/weight_init.h:    void gaussian_fill(vec_t *weight, cnn_size_t fan_in, cnn_size_t fan_out) {//Yao: deleted override
util/weight_init.h:    void fill(vec_t *weight, cnn_size_t fan_in, cnn_size_t fan_out) {//Yao: deleted override
util/weight_init.h:    void he_fill(vec_t *weight, cnn_size_t fan_in, cnn_size_t fan_out) {//Yao: deleted override
